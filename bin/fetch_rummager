#!/usr/bin/env ruby

require 'csv'
require 'unirest'
require 'active_support'
require 'active_support/core_ext/object/blank'

PRODUCTION_ENDPOINT = "https://www.gov.uk/api/search.json"

# STAGING IS BEHIND BY ~120 DOCUMENTS
STAGING_ENDPOINT = "https://www.staging.publishing.service.gov.uk/api/search.json"

ENDPOINT = STAGING_ENDPOINT

def build_csv(results)
  CSV.open("data/rummager", "a") do |csv|
    results.each do |result|
      base_path     = result["link"]
      organisations = fetch_resources("organisations", result)
      people        = fetch_resources("people", result)
      policies      = fetch_resources("policies", result)
      policy_groups = fetch_resources("policy_groups", result)
      specialist_sectors = fetch_resources("specialist_sectors", result)
      mainstream_browse_pages = fetch_resources("mainstream_browse_pages", result)

      csv << [base_path, 'policies', policies] if policies
      csv << [base_path, 'people', people] if people
      csv << [base_path, 'organisations', organisations] if organisations
      csv << [base_path, 'working_groups', policy_groups] if policy_groups
      csv << [base_path, 'topics', specialist_sectors] if specialist_sectors
      csv << [base_path, 'mainstream_browse_pages', mainstream_browse_pages] if mainstream_browse_pages
    end
  end
end

def fetch_resources(resources, result)
  return nil if result[resources].blank?

  result[resources].map do |resource|
    case resource
    when Hash
      resource["link"] if resource["link"].present?
    when String
      resource
    end
  end.join("|")
end

BATCH_SIZE = 3500

total_documents = Unirest.get("#{ENDPOINT}?count=0").body["total"]

puts "total documents: #{total_documents}"

num_pages = (total_documents / BATCH_SIZE) + 1

num_pages.times.each do |page|
  offset = page * BATCH_SIZE
  page_counter = num_pages - page

  puts "pages to go: #{page_counter}"
  puts "requesting offset: #{offset}"

  url = "#{ENDPOINT}?fields[]=link&fields[]=mainstream_browse_pages&fields[]=specialist_sectors&fields[]=organisations&fields[]=policy_groups&fields[]=content_id&count=#{BATCH_SIZE}&start=#{offset}"

  results = Unirest.get(url).body["results"]
  build_csv(results)
end
